{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97957a5",
   "metadata": {},
   "source": [
    ". Big data refers to extremely large sets of structured and unstructured data that cannot be handled with traditional methods\n",
    ". Apache Spark is a unified computing engine and a set of libraries for parallel data processing on\n",
    "computer clusters\n",
    ". We use Pache Spark for high speed data querying, analysis, and transformation with large data sets that is Big data.\n",
    "\n",
    ". Spark Applications consist of a driver process and a set of executor processes. The driver process\n",
    "runs your main() function, sits on a node in the cluster, and is responsible for three things:\n",
    "maintaining information about the Spark Application; responding to a user’s program or input;\n",
    "and analyzing, distributing, and scheduling work across the executors (discussed momentarily).\n",
    "The driver process is absolutely essential—it’s the heart of a Spark Application and maintains all\n",
    "relevant information during the lifetime of the application.\n",
    "The executors are responsible for actually carrying out the work that the driver assigns them.\n",
    "This means that each executor is responsible for only two things: executing code assigned to it\n",
    "by the driver, and reporting the state of the computation on that executor back to the driver node\n",
    "\n",
    ". We control your Spark Application through a driver process called the SparkSession\n",
    "\n",
    ".A DataFrame is the most common Structured API and simply represents a table of data with\n",
    "rows and columns\n",
    "\n",
    ". To allow every executor to perform work in parallel, Spark breaks up the data into chunks called\n",
    "partitions. A partition is a collection of rows that sit on one physical machine in your cluster. A\n",
    "DataFrame’s partitions represent how the data is physically distributed across the cluster of\n",
    "machines during execution\n",
    "\n",
    ".To “change” a DataFrame, you need to instruct Spark how you would like to\n",
    "modify it to do what you want. These instructions are called transformations.\n",
    "\n",
    ".Lazy evaulation means that Spark will wait until the very last moment to execute the graph of\n",
    "computation instructions. In Spark, instead of modifying the data immediately when you express\n",
    "some operation, you build up a plan of transformations that you would like to apply to your\n",
    "source data. By waiting until the last minute to execute the code, Spark compiles this plan from\n",
    "your raw DataFrame transformations to a streamlined physical plan that will run as efficiently as\n",
    "possible across the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3f2382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import IntegerType, LongType, StructField, StructType ,  StringType , FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad10980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c414ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 10:31:51 WARN Utils: Your hostname, TIGER03366 resolves to a loopback address: 127.0.1.1; using 172.26.198.76 instead (on interface eth0)\n",
      "22/09/01 10:31:51 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 10:31:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Basic Structured Operation\").getOrCreate()\n",
    "df = spark.range(500).toDF(\"numbers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b09802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|(numbers + 10)|\n",
      "+--------------+\n",
      "|            10|\n",
      "|            11|\n",
      "|            12|\n",
      "|            13|\n",
      "|            14|\n",
      "|            15|\n",
      "|            16|\n",
      "|            17|\n",
      "|            18|\n",
      "|            19|\n",
      "|            20|\n",
      "|            21|\n",
      "|            22|\n",
      "|            23|\n",
      "|            24|\n",
      "|            25|\n",
      "|            26|\n",
      "|            27|\n",
      "|            28|\n",
      "|            29|\n",
      "|            30|\n",
      "|            31|\n",
      "|            32|\n",
      "|            33|\n",
      "|            34|\n",
      "|            35|\n",
      "|            36|\n",
      "|            37|\n",
      "|            38|\n",
      "|            39|\n",
      "|            40|\n",
      "|            41|\n",
      "|            42|\n",
      "|            43|\n",
      "|            44|\n",
      "|            45|\n",
      "|            46|\n",
      "|            47|\n",
      "|            48|\n",
      "|            49|\n",
      "|            50|\n",
      "|            51|\n",
      "|            52|\n",
      "|            53|\n",
      "|            54|\n",
      "|            55|\n",
      "|            56|\n",
      "|            57|\n",
      "|            58|\n",
      "|            59|\n",
      "|            60|\n",
      "|            61|\n",
      "|            62|\n",
      "|            63|\n",
      "|            64|\n",
      "|            65|\n",
      "|            66|\n",
      "|            67|\n",
      "|            68|\n",
      "|            69|\n",
      "|            70|\n",
      "|            71|\n",
      "|            72|\n",
      "|            73|\n",
      "|            74|\n",
      "|            75|\n",
      "|            76|\n",
      "|            77|\n",
      "|            78|\n",
      "|            79|\n",
      "|            80|\n",
      "|            81|\n",
      "|            82|\n",
      "|            83|\n",
      "|            84|\n",
      "|            85|\n",
      "|            86|\n",
      "|            87|\n",
      "|            88|\n",
      "|            89|\n",
      "|            90|\n",
      "|            91|\n",
      "|            92|\n",
      "|            93|\n",
      "|            94|\n",
      "|            95|\n",
      "|            96|\n",
      "|            97|\n",
      "|            98|\n",
      "|            99|\n",
      "|           100|\n",
      "|           101|\n",
      "|           102|\n",
      "|           103|\n",
      "|           104|\n",
      "|           105|\n",
      "|           106|\n",
      "|           107|\n",
      "|           108|\n",
      "|           109|\n",
      "|           110|\n",
      "|           111|\n",
      "|           112|\n",
      "|           113|\n",
      "|           114|\n",
      "|           115|\n",
      "|           116|\n",
      "|           117|\n",
      "|           118|\n",
      "|           119|\n",
      "|           120|\n",
      "|           121|\n",
      "|           122|\n",
      "|           123|\n",
      "|           124|\n",
      "|           125|\n",
      "|           126|\n",
      "|           127|\n",
      "|           128|\n",
      "|           129|\n",
      "|           130|\n",
      "|           131|\n",
      "|           132|\n",
      "|           133|\n",
      "|           134|\n",
      "|           135|\n",
      "|           136|\n",
      "|           137|\n",
      "|           138|\n",
      "|           139|\n",
      "|           140|\n",
      "|           141|\n",
      "|           142|\n",
      "|           143|\n",
      "|           144|\n",
      "|           145|\n",
      "|           146|\n",
      "|           147|\n",
      "|           148|\n",
      "|           149|\n",
      "|           150|\n",
      "|           151|\n",
      "|           152|\n",
      "|           153|\n",
      "|           154|\n",
      "|           155|\n",
      "|           156|\n",
      "|           157|\n",
      "|           158|\n",
      "|           159|\n",
      "|           160|\n",
      "|           161|\n",
      "|           162|\n",
      "|           163|\n",
      "|           164|\n",
      "|           165|\n",
      "|           166|\n",
      "|           167|\n",
      "|           168|\n",
      "|           169|\n",
      "|           170|\n",
      "|           171|\n",
      "|           172|\n",
      "|           173|\n",
      "|           174|\n",
      "|           175|\n",
      "|           176|\n",
      "|           177|\n",
      "|           178|\n",
      "|           179|\n",
      "|           180|\n",
      "|           181|\n",
      "|           182|\n",
      "|           183|\n",
      "|           184|\n",
      "|           185|\n",
      "|           186|\n",
      "|           187|\n",
      "|           188|\n",
      "|           189|\n",
      "|           190|\n",
      "|           191|\n",
      "|           192|\n",
      "|           193|\n",
      "|           194|\n",
      "|           195|\n",
      "|           196|\n",
      "|           197|\n",
      "|           198|\n",
      "|           199|\n",
      "|           200|\n",
      "|           201|\n",
      "|           202|\n",
      "|           203|\n",
      "|           204|\n",
      "|           205|\n",
      "|           206|\n",
      "|           207|\n",
      "|           208|\n",
      "|           209|\n",
      "|           210|\n",
      "|           211|\n",
      "|           212|\n",
      "|           213|\n",
      "|           214|\n",
      "|           215|\n",
      "|           216|\n",
      "|           217|\n",
      "|           218|\n",
      "|           219|\n",
      "|           220|\n",
      "|           221|\n",
      "|           222|\n",
      "|           223|\n",
      "|           224|\n",
      "|           225|\n",
      "|           226|\n",
      "|           227|\n",
      "|           228|\n",
      "|           229|\n",
      "|           230|\n",
      "|           231|\n",
      "|           232|\n",
      "|           233|\n",
      "|           234|\n",
      "|           235|\n",
      "|           236|\n",
      "|           237|\n",
      "|           238|\n",
      "|           239|\n",
      "|           240|\n",
      "|           241|\n",
      "|           242|\n",
      "|           243|\n",
      "|           244|\n",
      "|           245|\n",
      "|           246|\n",
      "|           247|\n",
      "|           248|\n",
      "|           249|\n",
      "|           250|\n",
      "|           251|\n",
      "|           252|\n",
      "|           253|\n",
      "|           254|\n",
      "|           255|\n",
      "|           256|\n",
      "|           257|\n",
      "|           258|\n",
      "|           259|\n",
      "|           260|\n",
      "|           261|\n",
      "|           262|\n",
      "|           263|\n",
      "|           264|\n",
      "|           265|\n",
      "|           266|\n",
      "|           267|\n",
      "|           268|\n",
      "|           269|\n",
      "|           270|\n",
      "|           271|\n",
      "|           272|\n",
      "|           273|\n",
      "|           274|\n",
      "|           275|\n",
      "|           276|\n",
      "|           277|\n",
      "|           278|\n",
      "|           279|\n",
      "|           280|\n",
      "|           281|\n",
      "|           282|\n",
      "|           283|\n",
      "|           284|\n",
      "|           285|\n",
      "|           286|\n",
      "|           287|\n",
      "|           288|\n",
      "|           289|\n",
      "|           290|\n",
      "|           291|\n",
      "|           292|\n",
      "|           293|\n",
      "|           294|\n",
      "|           295|\n",
      "|           296|\n",
      "|           297|\n",
      "|           298|\n",
      "|           299|\n",
      "|           300|\n",
      "|           301|\n",
      "|           302|\n",
      "|           303|\n",
      "|           304|\n",
      "|           305|\n",
      "|           306|\n",
      "|           307|\n",
      "|           308|\n",
      "|           309|\n",
      "|           310|\n",
      "|           311|\n",
      "|           312|\n",
      "|           313|\n",
      "|           314|\n",
      "|           315|\n",
      "|           316|\n",
      "|           317|\n",
      "|           318|\n",
      "|           319|\n",
      "|           320|\n",
      "|           321|\n",
      "|           322|\n",
      "|           323|\n",
      "|           324|\n",
      "|           325|\n",
      "|           326|\n",
      "|           327|\n",
      "|           328|\n",
      "|           329|\n",
      "|           330|\n",
      "|           331|\n",
      "|           332|\n",
      "|           333|\n",
      "|           334|\n",
      "|           335|\n",
      "|           336|\n",
      "|           337|\n",
      "|           338|\n",
      "|           339|\n",
      "|           340|\n",
      "|           341|\n",
      "|           342|\n",
      "|           343|\n",
      "|           344|\n",
      "|           345|\n",
      "|           346|\n",
      "|           347|\n",
      "|           348|\n",
      "|           349|\n",
      "|           350|\n",
      "|           351|\n",
      "|           352|\n",
      "|           353|\n",
      "|           354|\n",
      "|           355|\n",
      "|           356|\n",
      "|           357|\n",
      "|           358|\n",
      "|           359|\n",
      "|           360|\n",
      "|           361|\n",
      "|           362|\n",
      "|           363|\n",
      "|           364|\n",
      "|           365|\n",
      "|           366|\n",
      "|           367|\n",
      "|           368|\n",
      "|           369|\n",
      "|           370|\n",
      "|           371|\n",
      "|           372|\n",
      "|           373|\n",
      "|           374|\n",
      "|           375|\n",
      "|           376|\n",
      "|           377|\n",
      "|           378|\n",
      "|           379|\n",
      "|           380|\n",
      "|           381|\n",
      "|           382|\n",
      "|           383|\n",
      "|           384|\n",
      "|           385|\n",
      "|           386|\n",
      "|           387|\n",
      "|           388|\n",
      "|           389|\n",
      "|           390|\n",
      "|           391|\n",
      "|           392|\n",
      "|           393|\n",
      "|           394|\n",
      "|           395|\n",
      "|           396|\n",
      "|           397|\n",
      "|           398|\n",
      "|           399|\n",
      "|           400|\n",
      "|           401|\n",
      "|           402|\n",
      "|           403|\n",
      "|           404|\n",
      "|           405|\n",
      "|           406|\n",
      "|           407|\n",
      "|           408|\n",
      "|           409|\n",
      "|           410|\n",
      "|           411|\n",
      "|           412|\n",
      "|           413|\n",
      "|           414|\n",
      "|           415|\n",
      "|           416|\n",
      "|           417|\n",
      "|           418|\n",
      "|           419|\n",
      "|           420|\n",
      "|           421|\n",
      "|           422|\n",
      "|           423|\n",
      "|           424|\n",
      "|           425|\n",
      "|           426|\n",
      "|           427|\n",
      "|           428|\n",
      "|           429|\n",
      "|           430|\n",
      "|           431|\n",
      "|           432|\n",
      "|           433|\n",
      "|           434|\n",
      "|           435|\n",
      "|           436|\n",
      "|           437|\n",
      "|           438|\n",
      "|           439|\n",
      "|           440|\n",
      "|           441|\n",
      "|           442|\n",
      "|           443|\n",
      "|           444|\n",
      "|           445|\n",
      "|           446|\n",
      "|           447|\n",
      "|           448|\n",
      "|           449|\n",
      "|           450|\n",
      "|           451|\n",
      "|           452|\n",
      "|           453|\n",
      "|           454|\n",
      "|           455|\n",
      "|           456|\n",
      "|           457|\n",
      "|           458|\n",
      "|           459|\n",
      "|           460|\n",
      "|           461|\n",
      "|           462|\n",
      "|           463|\n",
      "|           464|\n",
      "|           465|\n",
      "|           466|\n",
      "|           467|\n",
      "|           468|\n",
      "|           469|\n",
      "|           470|\n",
      "|           471|\n",
      "|           472|\n",
      "|           473|\n",
      "|           474|\n",
      "|           475|\n",
      "|           476|\n",
      "|           477|\n",
      "|           478|\n",
      "|           479|\n",
      "|           480|\n",
      "|           481|\n",
      "|           482|\n",
      "|           483|\n",
      "|           484|\n",
      "|           485|\n",
      "|           486|\n",
      "|           487|\n",
      "|           488|\n",
      "|           489|\n",
      "|           490|\n",
      "|           491|\n",
      "|           492|\n",
      "|           493|\n",
      "|           494|\n",
      "|           495|\n",
      "|           496|\n",
      "|           497|\n",
      "|           498|\n",
      "|           499|\n",
      "|           500|\n",
      "|           501|\n",
      "|           502|\n",
      "|           503|\n",
      "|           504|\n",
      "|           505|\n",
      "|           506|\n",
      "|           507|\n",
      "|           508|\n",
      "|           509|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df[\"numbers\"] + 10).show(df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aec0c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=0), Row(id=1)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(2).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04dade5",
   "metadata": {},
   "source": [
    "# Creating a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b23a3cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = spark.read.format(\"csv\").load(\"customer-orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82329df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|_c0| _c1|  _c2|\n",
      "+---+----+-----+\n",
      "| 44|8602|37.19|\n",
      "| 35|5368|65.89|\n",
      "|  2|3391|40.64|\n",
      "| 47|6694|14.98|\n",
      "| 29| 680|13.08|\n",
      "| 91|8900|24.59|\n",
      "| 70|3959|68.68|\n",
      "| 85|1733|28.53|\n",
      "| 53|9900|83.55|\n",
      "| 14|1505| 4.32|\n",
      "+---+----+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffd2f5c",
   "metadata": {},
   "source": [
    "# Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2f13abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: string (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e47acc40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('_c0', StringType(), True), StructField('_c1', StringType(), True), StructField('_c2', StringType(), True)])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.format(\"csv\").load(\"customer-orders.csv\").schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d3fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "mySchema = StructType([\n",
    "    StructField(\"customer_id\" , IntegerType() , True),\n",
    "    StructField(\"item_id\", IntegerType() , True),\n",
    "    StructField(\"Amount\" , FloatType() , True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c7042f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_new_df = spark.read.schema(mySchema).csv(\"customer-orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f51033c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- customer_id: integer (nullable = true)\n",
      " |-- item_id: integer (nullable = true)\n",
      " |-- Amount: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36454281",
   "metadata": {},
   "source": [
    "# Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fff06729",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81530d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'customer_id'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_new_df.customer_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31e817d",
   "metadata": {},
   "source": [
    "# Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba70fb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(customer_id=44, item_id=8602, Amount=37.189998626708984)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_new_df.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98babcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "myRow = Row(\"Hello\", None, 1, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "399f725e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Row('Hello', None, 1, False)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4800b0aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRow[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d113a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myRow[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91d81c0",
   "metadata": {},
   "source": [
    "# Creating the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9168365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType\n",
    "myManualSchema = StructType([\n",
    "StructField(\"some\", StringType(), True),\n",
    "StructField(\"col\", StringType(), True),\n",
    "StructField(\"names\", LongType(), False)\n",
    "])\n",
    "myRow = Row(\"Hello\", None, 1)\n",
    "myDf = spark.createDataFrame([myRow], myManualSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d7286",
   "metadata": {},
   "source": [
    "# Select and SelectExpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "88bb6ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|         44|\n",
      "|         35|\n",
      "+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.select(\"customer_id\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05c26b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "|customer_id|item_id|\n",
      "+-----------+-------+\n",
      "|         44|   8602|\n",
      "|         35|   5368|\n",
      "|          2|   3391|\n",
      "|         47|   6694|\n",
      "|         29|    680|\n",
      "|         91|   8900|\n",
      "|         70|   3959|\n",
      "|         85|   1733|\n",
      "|         53|   9900|\n",
      "|         14|   1505|\n",
      "|         51|   3378|\n",
      "|         42|   6926|\n",
      "|          2|   4424|\n",
      "|         79|   9291|\n",
      "|         50|   3901|\n",
      "|         20|   6633|\n",
      "|         15|   6148|\n",
      "|         44|   8331|\n",
      "|          5|   3505|\n",
      "|         48|   5539|\n",
      "+-----------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.select(\"customer_id\" , \"item_id\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae359d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|Customer_ID|\n",
      "+-----------+\n",
      "|         44|\n",
      "|         35|\n",
      "|          2|\n",
      "|         47|\n",
      "|         29|\n",
      "|         91|\n",
      "|         70|\n",
      "|         85|\n",
      "|         53|\n",
      "|         14|\n",
      "+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.select(func.expr(\"customer_id as Customer_ID\")).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1898d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         44|   8602| 37.19|\n",
      "|         35|   5368| 65.89|\n",
      "|          2|   3391| 40.64|\n",
      "|         47|   6694| 14.98|\n",
      "|         29|    680| 13.08|\n",
      "|         91|   8900| 24.59|\n",
      "|         70|   3959| 68.68|\n",
      "|         85|   1733| 28.53|\n",
      "|         53|   9900| 83.55|\n",
      "|         14|   1505|  4.32|\n",
      "+-----------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3516850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----------------------+\n",
      "|count(DISTINCT customer_id)|count(DISTINCT item_id)|\n",
      "+---------------------------+-----------------------+\n",
      "|                        100|                   6369|\n",
      "+---------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.selectExpr(\"count(distinct(customer_id))\" , \"count(distinct(item_id))\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fce184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       sum(Amount)|\n",
      "+------------------+\n",
      "|500489.18006796576|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.selectExpr(\"sum(Amount)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951225df",
   "metadata": {},
   "source": [
    "# Adding Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1e8a959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+---------+\n",
      "|customer_id|item_id|Amount|numberOne|\n",
      "+-----------+-------+------+---------+\n",
      "|         44|   8602| 37.19|        1|\n",
      "|         35|   5368| 65.89|        1|\n",
      "|          2|   3391| 40.64|        1|\n",
      "|         47|   6694| 14.98|        1|\n",
      "|         29|    680| 13.08|        1|\n",
      "|         91|   8900| 24.59|        1|\n",
      "|         70|   3959| 68.68|        1|\n",
      "|         85|   1733| 28.53|        1|\n",
      "|         53|   9900| 83.55|        1|\n",
      "|         14|   1505|  4.32|        1|\n",
      "+-----------+-------+------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "customer_new_df.withColumn(\"numberOne\", lit(1)).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b520d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+-------------+\n",
      "|customer_id|item_id|Amount|withinCountry|\n",
      "+-----------+-------+------+-------------+\n",
      "|         44|   8602| 37.19|        false|\n",
      "|         35|   5368| 65.89|        false|\n",
      "+-----------+-------+------+-------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.withColumn(\"withinCountry\", func.expr(\"customer_id = item_id\")).show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e537b182",
   "metadata": {},
   "source": [
    "# Renaming columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f8321256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['customer_id', 'item_id', 'Amount']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a640e0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "renamed_df = customer_new_df.withColumnRenamed(\"customer_id\" , \"Customer_ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c820a48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Customer_ID', 'item_id', 'Amount']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "renamed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63802f94",
   "metadata": {},
   "source": [
    "# Changing a Column’s Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6abe3833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+-----+\n",
      "|Customer_ID|item_id|Amount|count|\n",
      "+-----------+-------+------+-----+\n",
      "|         44|   8602| 37.19|100.0|\n",
      "|         35|   5368| 65.89|100.0|\n",
      "|          2|   3391| 40.64|100.0|\n",
      "|         47|   6694| 14.98|100.0|\n",
      "|         29|    680| 13.08|100.0|\n",
      "+-----------+-------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "renamed_df.withColumn(\"count\" , func.expr(\"100\").cast(\"float\").alias(\"constant\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee327ca",
   "metadata": {},
   "source": [
    "# Filtering Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "98935a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         35|   5368| 65.89|\n",
      "|         70|   3959| 68.68|\n",
      "|         53|   9900| 83.55|\n",
      "|         42|   6926| 57.77|\n",
      "|          2|   4424| 55.77|\n",
      "|         15|   6148| 65.53|\n",
      "|         44|   8331| 99.19|\n",
      "|          5|   3505| 64.18|\n",
      "|         36|   8274| 88.64|\n",
      "|         57|    963| 57.91|\n",
      "|         12|   4396| 72.62|\n",
      "|         22|   7161| 56.06|\n",
      "|          0|   3479| 97.22|\n",
      "|         88|   1272|  80.7|\n",
      "|         86|   9254|  71.9|\n",
      "|         40|   3083| 72.95|\n",
      "|         98|     30| 86.56|\n",
      "|         51|   2187| 84.57|\n",
      "|         91|   8363| 64.42|\n",
      "|         14|   5388| 77.77|\n",
      "+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.filter(func.col(\"amount\") > 50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d4daf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         35|   5368| 65.89|\n",
      "|         70|   3959| 68.68|\n",
      "|         53|   9900| 83.55|\n",
      "|         42|   6926| 57.77|\n",
      "|          2|   4424| 55.77|\n",
      "|         15|   6148| 65.53|\n",
      "|         44|   8331| 99.19|\n",
      "|          5|   3505| 64.18|\n",
      "|         36|   8274| 88.64|\n",
      "|         57|    963| 57.91|\n",
      "|         12|   4396| 72.62|\n",
      "|         22|   7161| 56.06|\n",
      "|          0|   3479| 97.22|\n",
      "|         88|   1272|  80.7|\n",
      "|         86|   9254|  71.9|\n",
      "|         40|   3083| 72.95|\n",
      "|         98|     30| 86.56|\n",
      "|         51|   2187| 84.57|\n",
      "|         91|   8363| 64.42|\n",
      "|         14|   5388| 77.77|\n",
      "+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.where(func.col(\"amount\") > 50).where(func.col(\"customer_id\") !=10 ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a9782f",
   "metadata": {},
   "source": [
    "# Getting Unique Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b506ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|         31|\n",
      "|         85|\n",
      "|         65|\n",
      "|         53|\n",
      "|         78|\n",
      "|         34|\n",
      "|         81|\n",
      "|         28|\n",
      "|         76|\n",
      "|         27|\n",
      "|         26|\n",
      "|         44|\n",
      "|         12|\n",
      "|         91|\n",
      "|         22|\n",
      "|         93|\n",
      "|         47|\n",
      "|          1|\n",
      "|         52|\n",
      "|         13|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_new_df.select(\"customer_id\").distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd28fdb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_new_df.select(\"customer_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a8b952",
   "metadata": {},
   "source": [
    "# Random Samples and Random Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fa718bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_new_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c78add30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2975"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 25\n",
    "fraction = 0.3\n",
    "withreplacement = False\n",
    "customer_new_df.sample(withreplacement, fraction , seed).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "25dea788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7967 2033\n"
     ]
    }
   ],
   "source": [
    "dataframes = customer_new_df.randomSplit([0.8 , 0.2] , seed)\n",
    "print(dataframes[0].count() , dataframes[1].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b30e331",
   "metadata": {},
   "source": [
    "# Concatenating and Appending Rows (Union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a220fc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c081a646",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_schema = customer_new_df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73986072",
   "metadata": {},
   "outputs": [],
   "source": [
    "newRows = [\n",
    "    Row(17 , 60 , 100.0),\n",
    "    Row(17 , 17 , 200.0)\n",
    "]\n",
    "\n",
    "parallelizedRows = spark.sparkContext.parallelize(newRows)\n",
    "df_new = spark.createDataFrame(parallelizedRows, old_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc80e842",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = customer_new_df.union(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d2d2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         17|     17| 200.0|\n",
      "+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(func.col(\"customer_id\") == 17).where(func.col(\"item_id\") ==17).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9119510c",
   "metadata": {},
   "source": [
    "# Sorting Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fddc8613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         33|   9769|   0.0|\n",
      "|         76|   5339|   0.0|\n",
      "|         38|   7808|  0.01|\n",
      "|         10|   4612|  0.01|\n",
      "|         54|   7193|  0.02|\n",
      "|         50|    269|  0.03|\n",
      "|         11|     97|  0.05|\n",
      "|         30|   7862|  0.09|\n",
      "|         18|   4019|   0.1|\n",
      "|          1|   5550|   0.1|\n",
      "|         65|   6431|   0.1|\n",
      "|         95|   2830|  0.11|\n",
      "|         67|   3273|  0.12|\n",
      "|         98|   2656|  0.13|\n",
      "|         70|   7644|  0.14|\n",
      "|         10|   8064|  0.15|\n",
      "|         52|   5358|  0.17|\n",
      "|         66|   5900|  0.17|\n",
      "|         79|   9412|  0.18|\n",
      "|         30|   1726|  0.19|\n",
      "+-----------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"amount\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3dbf9ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         17|     17| 200.0|\n",
      "|         17|     60| 100.0|\n",
      "|         73|   7875| 99.99|\n",
      "|         73|   7152| 99.99|\n",
      "|         33|   2844| 99.97|\n",
      "+-----------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(func.col(\"Amount\").desc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f3532f",
   "metadata": {},
   "source": [
    "# Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1520ce3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         44|   8602| 37.19|\n",
      "|         35|   5368| 65.89|\n",
      "+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.limit(2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eaa133c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+------+\n",
      "|customer_id|item_id|Amount|\n",
      "+-----------+-------+------+\n",
      "|         17|     17| 200.0|\n",
      "|         17|     60| 100.0|\n",
      "+-----------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(func.col(\"Amount\").desc()).limit(2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f318a62",
   "metadata": {},
   "source": [
    "# Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "320f54cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "75d809c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: int, item_id: int, Amount: float]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "54ca54e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[customer_id: int, item_id: int, Amount: float]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repartition(5, func.col(\"Amount\")).coalesce(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96cb5c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- _c1: string (nullable = true)\n",
      " |-- _c2: integer (nullable = true)\n",
      " |-- _c3: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends = spark.read.format(\"csv\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"fakefriends.csv\")\n",
    "friends.printSchema()\n",
    "friends.createOrReplaceTempView(\"dfTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10d81688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---+\n",
      "|_c0|     _c1|_c2|_c3|\n",
      "+---+--------+---+---+\n",
      "|  0|    Will| 33|385|\n",
      "|  1|Jean-Luc| 26|  2|\n",
      "|  2|    Hugh| 55|221|\n",
      "|  3|  Deanna| 40|465|\n",
      "|  4|   Quark| 68| 21|\n",
      "+---+--------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f0ebeb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---+\n",
      "|_c0|     _c1|_c2|_c3|\n",
      "+---+--------+---+---+\n",
      "|  1|Jean-Luc| 26|  2|\n",
      "|  2|    Hugh| 55|221|\n",
      "|  3|  Deanna| 40|465|\n",
      "|  4|   Quark| 68| 21|\n",
      "|  5|  Weyoun| 59|318|\n",
      "+---+--------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.where(func.col(\"_c2\") != 33).select(\"*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ee3fb2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---+---+\n",
      "|_c0|   _c1|_c2|_c3|\n",
      "+---+------+---+---+\n",
      "|  2|  Hugh| 55|221|\n",
      "|  3|Deanna| 40|465|\n",
      "|  4| Quark| 68| 21|\n",
      "|  5|Weyoun| 59|318|\n",
      "|  6|Gowron| 37|220|\n",
      "+---+------+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "age_condition = func.col(\"_c2\") > 33\n",
    "friends_condition = func.col(\"_c3\") > 10\n",
    "\n",
    "friends.where(age_condition & friends_condition).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5a6d67",
   "metadata": {},
   "source": [
    "# Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "39fd8c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|Square_of_age|\n",
      "+-------------+\n",
      "|       1089.0|\n",
      "|        676.0|\n",
      "|       3025.0|\n",
      "|       1600.0|\n",
      "|       4624.0|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.selectExpr(\"POWER(_C2,2) as Square_of_age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a94d613f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|_c2|ROUND|\n",
      "+---+-----+\n",
      "| 33|  6.6|\n",
      "| 26|  5.2|\n",
      "| 55| 11.0|\n",
      "| 40|  8.0|\n",
      "| 68| 13.6|\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.selectExpr(\"_c2\" , \"round(_c2/5 ,2) as ROUND\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fefdc3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|      corr(_c2, _c3)|\n",
      "+--------------------+\n",
      "|0.027639181401853022|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.corr(\"_c2\" , \"_c3\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6daf9d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+----+------------------+-----------------+\n",
      "|summary|              _c0| _c1|               _c2|              _c3|\n",
      "+-------+-----------------+----+------------------+-----------------+\n",
      "|  count|              500| 500|               500|              500|\n",
      "|   mean|            249.5|null|            43.708|          248.532|\n",
      "| stddev|144.4818327679989|null|14.864340996711995|147.2217288680643|\n",
      "|    min|                0| Ben|                18|                1|\n",
      "|    max|              499|Worf|                69|              499|\n",
      "+-------+-----------------+----+------------------+-----------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "friends.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "39803464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[49.38999938964844]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colName = \"Amount\"\n",
    "quantileProbs = [0.5]\n",
    "relError = 0.05\n",
    "df.stat.approxQuantile(colName, quantileProbs, relError)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2b73491b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_c0', '_c1', '_c2', '_c3']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71c4d710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---+\n",
      "|_c0|     _c1|_c2|_c3|\n",
      "+---+--------+---+---+\n",
      "|  0|    Will| 33|385|\n",
      "|  1|Jean-Luc| 26|  2|\n",
      "+---+--------+---+---+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d523d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = friends.withColumnRenamed(\"_c1\" , \"Name\").withColumnRenamed(\"_c2\" , \"Age\").withColumnRenamed(\"_c3\" , \"NoFriends\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41854588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|initcap(Name)|\n",
      "+-------------+\n",
      "|         Will|\n",
      "|     Jean-luc|\n",
      "|         Hugh|\n",
      "|       Deanna|\n",
      "|        Quark|\n",
      "+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.initcap(\"Name\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5ae842",
   "metadata": {},
   "source": [
    "# Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1881f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|lower(Name)|upper(Name)|\n",
      "+-----------+-----------+\n",
      "|       will|       WILL|\n",
      "|   jean-luc|   JEAN-LUC|\n",
      "|       hugh|       HUGH|\n",
      "|     deanna|     DEANNA|\n",
      "|      quark|      QUARK|\n",
      "+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.lower(func.col(\"Name\")) , func.upper(func.col(\"Name\"))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "86e877ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+---+----------+\n",
      "| ltrim| rtrim| trim| lp|        rp|\n",
      "+------+------+-----+---+----------+\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "|HELLO | HELLO|HELLO|HEL|HELLO     |\n",
      "+------+------+-----+---+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(\n",
    "func.ltrim(lit(\" HELLO \")).alias(\"ltrim\"),\n",
    "func.rtrim(lit(\" HELLO \")).alias(\"rtrim\"),\n",
    "func.trim(lit(\" HELLO \")).alias(\"trim\"),\n",
    "func.lpad(lit(\"HELLO\"), 3, \" \").alias(\"lp\"),\n",
    "func.rpad(lit(\"HELLO\"), 10, \" \").alias(\"rp\")).show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88f93979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|color_Name|    Name|\n",
      "+----------+--------+\n",
      "|      Will|    Will|\n",
      "|  Jean-Luc|Jean-Luc|\n",
      "+----------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "regex_string = \"BLACK|WHITE|RED|GREEN|BLUE\"\n",
    "friends.select(\n",
    "regexp_replace(func.col(\"Name\"), regex_string, \"COLOR\").alias(\"color_Name\"),\n",
    "func.col(\"Name\")).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5b53fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+--------+\n",
      "|translate(Name, 1375, leet)|    Name|\n",
      "+---------------------------+--------+\n",
      "|                       Will|    Will|\n",
      "|                   Jean-Luc|Jean-Luc|\n",
      "+---------------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import translate\n",
    "friends.select(translate(func.col(\"Name\"), \"1375\", \"leet\"),func.col(\"Name\"))\\\n",
    ".show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743929d",
   "metadata": {},
   "source": [
    "# Date Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dc819a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: long (nullable = false)\n",
      " |-- today: date (nullable = false)\n",
      " |-- now: timestamp (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date, current_timestamp\n",
    "dateDF = spark.range(10)\\\n",
    ".withColumn(\"today\", current_date())\\\n",
    ".withColumn(\"now\", current_timestamp())\n",
    "dateDF.createOrReplaceTempView(\"dateTable\")\n",
    "\n",
    "dateDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4b11b7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+\n",
      "| id|     today|                 now|\n",
      "+---+----------+--------------------+\n",
      "|  0|2022-09-01|2022-09-01 10:32:...|\n",
      "|  1|2022-09-01|2022-09-01 10:32:...|\n",
      "|  2|2022-09-01|2022-09-01 10:32:...|\n",
      "|  3|2022-09-01|2022-09-01 10:32:...|\n",
      "|  4|2022-09-01|2022-09-01 10:32:...|\n",
      "|  5|2022-09-01|2022-09-01 10:32:...|\n",
      "|  6|2022-09-01|2022-09-01 10:32:...|\n",
      "|  7|2022-09-01|2022-09-01 10:32:...|\n",
      "|  8|2022-09-01|2022-09-01 10:32:...|\n",
      "|  9|2022-09-01|2022-09-01 10:32:...|\n",
      "+---+----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ec741b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2022-08-27|        2022-09-06|\n",
      "+------------------+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import date_add, date_sub\n",
    "dateDF.select(date_sub(func.col(\"today\"), 5), date_add(func.col(\"today\"), 5)).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6ad9f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.withColumn(\"week_ago\", date_sub(func.col(\"today\"), 7))\\\n",
    ".select(func.datediff(func.col(\"week_ago\"), func.col(\"today\"))).show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d0396a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------+\n",
      "|months_between(start, end, true)|\n",
      "+--------------------------------+\n",
      "|                     -0.03225806|\n",
      "+--------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dateDF.select(\n",
    "func.to_date(lit(\"2016-01-01\")).alias(\"start\"),\n",
    "func.to_date(lit(\"2016-01-02\")).alias(\"end\"))\\\n",
    ".select(func.months_between(func.col(\"start\"), func.col(\"end\"))).show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "12ea0e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: int, Name: string, Age: int, NoFriends: int]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.na.drop(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9d99ae79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+---------+\n",
      "|_c0|    Name|Age|NoFriends|\n",
      "+---+--------+---+---------+\n",
      "|  0|    Will| 33|      385|\n",
      "|  1|Jean-Luc| 26|        2|\n",
      "|  2|    Hugh| 55|      221|\n",
      "|  3|  Deanna| 40|      465|\n",
      "|  4|   Quark| 68|       21|\n",
      "+---+--------+---+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a73fbe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|split(Name,  , -1)|\n",
      "+------------------+\n",
      "|            [Will]|\n",
      "|        [Jean-Luc]|\n",
      "|            [Hugh]|\n",
      "|          [Deanna]|\n",
      "|           [Quark]|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.split(\"Name\",\" \")).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "68272d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|size(split(Name,  , -1))|\n",
      "+------------------------+\n",
      "|                       1|\n",
      "|                       1|\n",
      "|                       1|\n",
      "|                       1|\n",
      "|                       1|\n",
      "+------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.size(func.split(\"Name\",\" \"))).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "64b3f0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|     complex_map|\n",
      "+----------------+\n",
      "|    {Will -> 33}|\n",
      "|{Jean-Luc -> 26}|\n",
      "+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import create_map\n",
    "friends.select(create_map(func.col(\"Name\"), func.col(\"Age\")).alias(\"complex_map\"))\\\n",
    ".show(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8ca984cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|complex_map[Will]|\n",
      "+-----------------+\n",
      "|               33|\n",
      "|             null|\n",
      "|             null|\n",
      "|             null|\n",
      "|             null|\n",
      "|             null|\n",
      "|             null|\n",
      "|               54|\n",
      "|             null|\n",
      "|             null|\n",
      "+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(create_map(func.col(\"Name\"), func.col(\"Age\")).alias(\"complex_map\"))\\\n",
    ".selectExpr(\"complex_map['Will']\").show(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa2fdb0",
   "metadata": {},
   "source": [
    "# User Defined function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af3745eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_friends(x):\n",
    "    return x*2\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "double_friendsUDF = udf(double_friends)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e52ea04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|double_friends(nofriends)|\n",
      "+-------------------------+\n",
      "|                      770|\n",
      "|                        4|\n",
      "+-------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "friends.select(double_friendsUDF(col(\"nofriends\"))).show(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194cd913",
   "metadata": {},
   "source": [
    "# Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "57374646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Name)|\n",
      "+-----------+\n",
      "|        500|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.count(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b7a580d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Name)|\n",
      "+--------------------+\n",
      "|                  30|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.countDistinct(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1bb9ba3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|approx_count_distinct(Name)|\n",
      "+---------------------------+\n",
      "|                         25|\n",
      "+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.approx_count_distinct(\"Name\" , 0.1)).show() # here the 0.1 is the max error "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc501f8",
   "metadata": {},
   "source": [
    "# first and last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ac6706f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+\n",
      "|first(Name)|last(Name)|\n",
      "+-----------+----------+\n",
      "|       Will|     Leeta|\n",
      "+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.first(\"Name\"),func.last(\"Name\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f944f6ba",
   "metadata": {},
   "source": [
    "# min and max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45617286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|max(NoFriends)|min(NoFriends)|\n",
      "+--------------+--------------+\n",
      "|           499|             1|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.max(\"NoFriends\"),func.min(\"NoFriends\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c94ebeb",
   "metadata": {},
   "source": [
    "# Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "555b0ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|sum(Nofriends)|\n",
      "+--------------+\n",
      "|        124266|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.sum(\"Nofriends\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1fd1970c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shashank1/.local/lib/python3.8/site-packages/pyspark/sql/functions.py:315: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
      "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|sum(DISTINCT Age)|\n",
      "+-----------------+\n",
      "|             2262|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.sumDistinct(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94077930",
   "metadata": {},
   "source": [
    "# Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f5ea4b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------+---------+\n",
      "|count(Age)|sum(Age)|avg(Age)|mean(Age)|\n",
      "+----------+--------+--------+---------+\n",
      "|       500|   21854|  43.708|   43.708|\n",
      "+----------+--------+--------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.count(\"Age\") , func.sum(\"Age\") , func.avg(\"Age\") , func.expr(\"mean(Age)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50060c0",
   "metadata": {},
   "source": [
    "# Variance and Standard Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "87c2f10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+-----------------+------------------+\n",
      "|      var_pop(Age)|     var_samp(Age)|  stddev_pop(Age)|  stddev_samp(Age)|\n",
      "+------------------+------------------+-----------------+------------------+\n",
      "|220.50673599999988|220.94863326653297|14.84946921610331|14.864340996711995|\n",
      "+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.var_pop(\"Age\"), func.var_samp(\"Age\"),\n",
    "func.stddev_pop(\"Age\"), func.stddev_samp(\"Age\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f96179",
   "metadata": {},
   "source": [
    "# Covariance and Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62ad5e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+-------------------------+\n",
      "|corr(Age, Nofriends)|covar_samp(Age, Nofriends)|covar_pop(Age, Nofriends)|\n",
      "+--------------------+--------------------------+-------------------------+\n",
      "|0.027639181401853022|        60.484312625250496|                60.363344|\n",
      "+--------------------+--------------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.select(func.corr(\"Age\" , \"Nofriends\"), func.covar_samp(\"Age\" , \"Nofriends\"),\n",
    "func.covar_pop(\"Age\" , \"Nofriends\")).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e717bb",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "cc59444c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|Age|count|\n",
      "+---+-----+\n",
      "| 31|    8|\n",
      "| 65|    5|\n",
      "| 53|    7|\n",
      "| 34|    6|\n",
      "| 28|   10|\n",
      "| 26|   17|\n",
      "| 27|    8|\n",
      "| 44|   12|\n",
      "| 22|    7|\n",
      "| 47|    9|\n",
      "| 52|   11|\n",
      "| 40|   17|\n",
      "| 20|    5|\n",
      "| 57|   12|\n",
      "| 54|   13|\n",
      "| 48|   10|\n",
      "| 19|   11|\n",
      "| 64|   12|\n",
      "| 41|    9|\n",
      "| 43|    7|\n",
      "+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.groupBy(\"Age\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "85844f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----------------+\n",
      "|Age|func_count|count(Nofriends)|\n",
      "+---+----------+----------------+\n",
      "| 31|         8|               8|\n",
      "| 65|         5|               5|\n",
      "| 53|         7|               7|\n",
      "| 34|         6|               6|\n",
      "| 28|        10|              10|\n",
      "| 26|        17|              17|\n",
      "| 27|         8|               8|\n",
      "| 44|        12|              12|\n",
      "| 22|         7|               7|\n",
      "| 47|         9|               9|\n",
      "| 52|        11|              11|\n",
      "| 40|        17|              17|\n",
      "| 20|         5|               5|\n",
      "| 57|        12|              12|\n",
      "| 54|        13|              13|\n",
      "| 48|        10|              10|\n",
      "| 19|        11|              11|\n",
      "| 64|        12|              12|\n",
      "| 41|         9|               9|\n",
      "| 43|         7|               7|\n",
      "+---+----------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.groupBy(\"Age\").agg(func.count(\"Nofriends\").alias(\"func_count\") , func.expr(\"count(Nofriends)\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4b2d9d",
   "metadata": {},
   "source": [
    "# Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6cc87a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import desc\n",
    "windowSpec = Window\\\n",
    ".partitionBy(\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a5eec342",
   "metadata": {},
   "outputs": [],
   "source": [
    "maxFriends = func.max(func.col(\"Nofriends\")).over(windowSpec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf04a1c",
   "metadata": {},
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c17801ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType([StructField('id', IntegerType(), True), \\\n",
    "    StructField('name', StringType(), True), StructField('graduate_program', IntegerType(), True), \\\n",
    "        StructField('spark_status',IntegerType())])\n",
    "\n",
    "schema_2 = StructType([StructField('id', IntegerType(), True), \\\n",
    "    StructField('degree', StringType(), True), StructField('department', StringType(), True), \\\n",
    "        StructField('school',StringType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e10545f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = spark.createDataFrame([\n",
    "(0, \"Bill Chambers\", 0, [100]),\n",
    "(1, \"Matei Zaharia\", 1, [500, 250, 100]),\n",
    "(2, \"Michael Armbrust\", 1, [250, 100])])\\\n",
    ".toDF(\"id\", \"name\", \"graduate_program\", \"spark_status\")\n",
    "graduateProgram = spark.createDataFrame([\n",
    "(0, \"Masters\", \"School of Information\", \"UC Berkeley\"),\n",
    "(2, \"Masters\", \"EECS\", \"UC Berkeley\"),\n",
    "(1, \"Ph.D.\", \"EECS\", \"UC Berkeley\")])\\\n",
    ".toDF(\"id\", \"degree\", \"department\", \"school\")\n",
    "sparkStatus = spark.createDataFrame([\n",
    "(500, \"Vice President\"),\n",
    "(250, \"PMC Member\"),\n",
    "(100, \"Contributor\")])\\\n",
    ".toDF(\"id\", \"status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f9a1ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n",
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n",
      "+---+--------------+\n",
      "| id|        status|\n",
      "+---+--------------+\n",
      "|500|Vice President|\n",
      "|250|    PMC Member|\n",
      "|100|   Contributor|\n",
      "+---+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()\n",
    "graduateProgram.show()\n",
    "sparkStatus.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d80a3d",
   "metadata": {},
   "source": [
    "## Inner join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ce8533aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "join_expression = person[\"id\"] == graduateProgram[\"id\"]\n",
    "person.join(graduateProgram, join_expression).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4909f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"inner\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a23bbc",
   "metadata": {},
   "source": [
    "## Outer Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d7a224cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"outer\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf0202",
   "metadata": {},
   "source": [
    "## Left Outer Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "79b1db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "|  5|        shashank|               0|          [500]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = Row(5,\"shashank\",0,[500])\n",
    "temp = spark.createDataFrame([row])\n",
    "person = person.union(temp)\n",
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67c8d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+----+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status|  id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+----+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|   0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|   1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|   2|Masters|                EECS|UC Berkeley|\n",
      "|  5|        shashank|               0|          [500]|null|   null|                null|       null|\n",
      "+---+----------------+----------------+---------------+----+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_outer\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26d13aa",
   "metadata": {},
   "source": [
    "## Right Outer Joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5024dcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------------------+-----------+\n",
      "| id| degree|          department|     school|\n",
      "+---+-------+--------------------+-----------+\n",
      "|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  6| Master|        Data Science|        UNT|\n",
      "+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "row = (6,\"Master\",\"Data Science\",\"UNT\")\n",
    "temp = spark.createDataFrame([row])\n",
    "graduateProgram = graduateProgram.union(temp)\n",
    "graduateProgram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "fcb5eced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|   0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|   2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|   1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|null|            null|            null|           null|  6| Master|        Data Science|        UNT|\n",
      "+----+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"right_outer\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4908db",
   "metadata": {},
   "source": [
    "## Left Semi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61e410c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+\n",
      "| id|            name|graduate_program|   spark_status|\n",
      "+---+----------------+----------------+---------------+\n",
      "|  0|   Bill Chambers|               0|          [100]|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|\n",
      "+---+----------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_semi\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db75b0b9",
   "metadata": {},
   "source": [
    "## Left Anti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53539fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----------------+------------+\n",
      "| id|    name|graduate_program|spark_status|\n",
      "+---+--------+----------------+------------+\n",
      "|  5|shashank|               0|       [500]|\n",
      "+---+--------+----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType = \"left_anti\"\n",
    "person.join(graduateProgram, join_expression, joinType).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5388196",
   "metadata": {},
   "source": [
    "## Cross Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5405b314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 202:==========================================>          (105 + 8) / 131]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "| id|            name|graduate_program|   spark_status| id| degree|          department|     school|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "|  0|   Bill Chambers|               0|          [100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  0|   Bill Chambers|               0|          [100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  0|   Bill Chambers|               0|          [100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  0|   Bill Chambers|               0|          [100]|  6| Master|        Data Science|        UNT|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  1|   Matei Zaharia|               1|[500, 250, 100]|  6| Master|        Data Science|        UNT|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  2|Michael Armbrust|               1|     [250, 100]|  6| Master|        Data Science|        UNT|\n",
      "|  5|        shashank|               0|          [500]|  0|Masters|School of Informa...|UC Berkeley|\n",
      "|  5|        shashank|               0|          [500]|  2|Masters|                EECS|UC Berkeley|\n",
      "|  5|        shashank|               0|          [500]|  1|  Ph.D.|                EECS|UC Berkeley|\n",
      "|  5|        shashank|               0|          [500]|  6| Master|        Data Science|        UNT|\n",
      "+---+----------------+----------------+---------------+---+-------+--------------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "person.crossJoin(graduateProgram).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e6f39f",
   "metadata": {},
   "source": [
    "# Datasources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8ec3e9",
   "metadata": {},
   "source": [
    "# Basics of Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "28cadd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\") \\\n",
    ".option(\"path\", \"1800.csv\") \\\n",
    ".load()\n",
    "\n",
    "temp_df = temp_df.withColumnRenamed(\"_c0\" , \"satation\").withColumnRenamed(\"_c1\" , \"date\").withColumnRenamed(\"_c2\" , \"Temp\").withColumnRenamed(\"_c3\",\"Temp_value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "716d4fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "|   satation|    date|Temp|Temp_value| _c4| _c5|_c6| _c7|\n",
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "|ITE00100554|18000101|TMAX|       -75|null|null|  E|null|\n",
      "|ITE00100554|18000101|TMIN|      -148|null|null|  E|null|\n",
      "|GM000010962|18000101|PRCP|         0|null|null|  E|null|\n",
      "|EZE00100082|18000101|TMAX|       -86|null|null|  E|null|\n",
      "|EZE00100082|18000101|TMIN|      -135|null|null|  E|null|\n",
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4ad69b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.select(func.col(\"satation\"),func.col(\"date\"),func.col(\"Temp\") , func.col(\"Temp_value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "bcbc6f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+\n",
      "|   satation|    date|Temp|Temp_value|\n",
      "+-----------+--------+----+----------+\n",
      "|ITE00100554|18000101|TMAX|       -75|\n",
      "|ITE00100554|18000101|TMIN|      -148|\n",
      "|GM000010962|18000101|PRCP|         0|\n",
      "|EZE00100082|18000101|TMAX|       -86|\n",
      "|EZE00100082|18000101|TMIN|      -135|\n",
      "+-----------+--------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a665e5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 11:37:32 WARN ParseMode: OVERWRITE is not a valid parse mode. Using PERMISSIVE.\n"
     ]
    }
   ],
   "source": [
    "temp_df.write.format(\"csv\") \\\n",
    ".option(\"mode\", \"OVERWRITE\") \\\n",
    ".option(\"dateFormat\", \"yyyy-MM-dd\") \\\n",
    ".option(\"path\", \"temp.csv\") \\\n",
    ".save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432a3684",
   "metadata": {},
   "source": [
    "# CSV read and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d6fe8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile = spark.read.format(\"csv\")\\\n",
    ".option(\"mode\", \"FAILFAST\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"customer-orders.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fc93ef46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+-----+\n",
      "|_c0| _c1|  _c2|\n",
      "+---+----+-----+\n",
      "| 44|8602|37.19|\n",
      "| 35|5368|65.89|\n",
      "|  2|3391|40.64|\n",
      "| 47|6694|14.98|\n",
      "| 29| 680|13.08|\n",
      "+---+----+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "csvFile.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b9348026",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.write.format(\"csv\").mode(\"overwrite\").option(\"sep\", \"\\t\")\\\n",
    ".save(\"my-tsv-file.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe3fe49",
   "metadata": {},
   "source": [
    "# Json Read and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "dcb04f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"json\").option(\"mode\", \"FAILFAST\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"2010.json\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b1448fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.write.format(\"json\").mode(\"overwrite\").save(\"my-json-file.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6577f0a8",
   "metadata": {},
   "source": [
    "# Parquet Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "237818ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"parquet\")\\\n",
    ".load(\"file.parquet\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "5c8b85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    ".save(\"my-parquet-file.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa6d006",
   "metadata": {},
   "source": [
    "# ORC file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "55785a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "|    United States|              India|   69|\n",
      "|            Egypt|      United States|   24|\n",
      "|Equatorial Guinea|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.format(\"orc\").load(\"orc_file.orc\").show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "c335e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile.write.format(\"orc\").mode(\"overwrite\").save(\"my-json-file.orc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0f9542",
   "metadata": {},
   "source": [
    "# Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "829d2644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show databases\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4ed2733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "|         |datetable|       true|\n",
      "|         |  dftable|       true|\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ccfa5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = spark.read.format(\"csv\").option(\"inferSchema\", \"true\") \\\n",
    ".option(\"path\", \"1800.csv\") \\\n",
    ".load()\n",
    "\n",
    "temp_df = temp_df.withColumnRenamed(\"_c0\" , \"satation\").withColumnRenamed(\"_c1\" , \"date\").withColumnRenamed(\"_c2\" , \"Temp\").withColumnRenamed(\"_c3\",\"Temp_value\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "459df980",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.createOrReplaceTempView(\"temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "48a3f97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "|   satation|    date|Temp|Temp_value| _c4| _c5|_c6| _c7|\n",
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "|ITE00100554|18000101|TMAX|       -75|null|null|  E|null|\n",
      "|ITE00100554|18000101|TMIN|      -148|null|null|  E|null|\n",
      "|GM000010962|18000101|PRCP|         0|null|null|  E|null|\n",
      "|EZE00100082|18000101|TMAX|       -86|null|null|  E|null|\n",
      "|EZE00100082|18000101|TMIN|      -135|null|null|  E|null|\n",
      "+-----------+--------+----+----------+----+----+---+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp_table\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "ddf44a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"drop table temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "6a10ea7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE temp (Satation STRING, date STRING, temp STRING , temp_value LONG) using csv options (path '1800.csv')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "befe3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+\n",
      "|namespace|  tableName|isTemporary|\n",
      "+---------+-----------+-----------+\n",
      "|  default|    flights|      false|\n",
      "|  default|nested_data|      false|\n",
      "|  default|       temp|      false|\n",
      "|         |  datetable|       true|\n",
      "|         |    dftable|       true|\n",
      "|         | temp_table|       true|\n",
      "+---------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "5eef98bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 15:00:20 WARN HadoopFSUtils: The directory file:/home/shashank1/cloud_training/spark/spark-warehouse/1800.csv was not found. Was it deleted very recently?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO temp VALUES ('ITE00100554','18000101' , 'TMAX' , -75)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "b8a94709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['satation', 'date', 'Temp', 'Temp_value', '_c4', '_c5', '_c6', '_c7']"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c974fa16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"INSERT INTO temp \\\n",
    "               select satation,date,Temp,Temp_value from temp_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "02a7047d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+\n",
      "|   Satation|    date|temp|temp_value|\n",
      "+-----------+--------+----+----------+\n",
      "|ITE00100554|18000101|TMAX|       -75|\n",
      "|ITE00100554|18000101|TMIN|      -148|\n",
      "|GM000010962|18000101|PRCP|         0|\n",
      "|EZE00100082|18000101|TMAX|       -86|\n",
      "|EZE00100082|18000101|TMIN|      -135|\n",
      "|ITE00100554|18000102|TMAX|       -60|\n",
      "|ITE00100554|18000102|TMIN|      -125|\n",
      "|GM000010962|18000102|PRCP|         0|\n",
      "|EZE00100082|18000102|TMAX|       -44|\n",
      "|EZE00100082|18000102|TMIN|      -130|\n",
      "|ITE00100554|18000103|TMAX|       -23|\n",
      "|ITE00100554|18000103|TMIN|       -46|\n",
      "|GM000010962|18000103|PRCP|         4|\n",
      "|EZE00100082|18000103|TMAX|       -10|\n",
      "|EZE00100082|18000103|TMIN|       -73|\n",
      "|ITE00100554|18000104|TMAX|         0|\n",
      "|ITE00100554|18000104|TMIN|       -13|\n",
      "|GM000010962|18000104|PRCP|         0|\n",
      "|EZE00100082|18000104|TMAX|       -55|\n",
      "|EZE00100082|18000104|TMIN|       -74|\n",
      "+-----------+--------+----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "3df39ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/01 15:02:45 WARN HadoopFSUtils: The directory file:/home/shashank1/cloud_training/spark/spark-warehouse/2010.json was not found. Was it deleted very recently?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE TABLE flights_from_select USING parquet AS SELECT * FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "9e7af93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE flights_from_select\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e7fa5162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP TABLE IF EXISTS flights_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a0545de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CACHE TABLE flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "d19783a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"UNCACHE TABLE flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6563aaff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE VIEW just_usa_view AS SELECT * FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "854f6881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----------+\n",
      "|namespace|    tableName|isTemporary|\n",
      "+---------+-------------+-----------+\n",
      "|  default|      flights|      false|\n",
      "|  default|just_usa_view|      false|\n",
      "|  default|         temp|      false|\n",
      "|         |    datetable|       true|\n",
      "|         |      dftable|       true|\n",
      "|         |   temp_table|       true|\n",
      "+---------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "57d24948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP VIEW IF EXISTS just_usa_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d9c1e9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|  default|   flights|      false|\n",
      "|  default|      temp|      false|\n",
      "|         | datetable|       true|\n",
      "|         |   dftable|       true|\n",
      "|         |temp_table|       true|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "96d0ca13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "61a226c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE some_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "413467c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|  some_db|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "c9689934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE some_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "652abffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------+\n",
      "|namespace| tableName|isTemporary|\n",
      "+---------+----------+-----------+\n",
      "|         | datetable|       true|\n",
      "|         |   dftable|       true|\n",
      "|         |temp_table|       true|\n",
      "+---------+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "53785f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM default.flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "492fbd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|current_database()|\n",
      "+------------------+\n",
      "|           some_db|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT current_database()\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "602ac414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"USE default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6a6bffff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"DROP DATABASE IF EXISTS some_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "27d21592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0c7904d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+\n",
      "|   Satation|    date|temp|temp_value|\n",
      "+-----------+--------+----+----------+\n",
      "|ITE00100554|18000101|TMAX|       -75|\n",
      "|ITE00100554|18000101|TMIN|      -148|\n",
      "|GM000010962|18000101|PRCP|         0|\n",
      "|EZE00100082|18000101|TMAX|       -86|\n",
      "|EZE00100082|18000101|TMIN|      -135|\n",
      "+-----------+--------+----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "a4ab01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|new_column|\n",
      "+----------+\n",
      "|         1|\n",
      "|         0|\n",
      "|        -1|\n",
      "|         1|\n",
      "|         0|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark.sql( \" select case when temp = 'TMAX' THEN 1 when temp= 'TMIN' THEN 0 else -1 END as new_column from temp\" ).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "17707c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE VIEW IF NOT EXISTS nested_data AS SELECT (DEST_COUNTRY_NAME, ORIGIN_COUNTRY_NAME) as country, count FROM flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "d4962a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|country|count|\n",
      "+-------+-----+\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM nested_data\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "971842e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------+\n",
      "|DEST_COUNTRY_NAME|array(1, 2, 3)|\n",
      "+-----------------+--------------+\n",
      "+-----------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DEST_COUNTRY_NAME, ARRAY(1, 2, 3) FROM flights\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "efb9f219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|square_temp(temp_value)|\n",
      "+-----------------------+\n",
      "|                   5625|\n",
      "|                  21904|\n",
      "|                      0|\n",
      "|                   7396|\n",
      "|                  18225|\n",
      "|                   3600|\n",
      "|                  15625|\n",
      "|                      0|\n",
      "|                   1936|\n",
      "|                  16900|\n",
      "+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def square_temp(x):\n",
    "    return x**2\n",
    "\n",
    "spark.udf.register(\"square_temp\", square_temp,IntegerType())\n",
    "\n",
    "spark.sql(\"select square_temp(temp_value) from temp\").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cd2eeabb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+----+----------+\n",
      "|   Satation|    date|temp|temp_value|\n",
      "+-----------+--------+----+----------+\n",
      "|ITE00100554|18000101|TMIN|      -148|\n",
      "+-----------+--------+----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from temp where temp_value = ( select min(temp_value) from temp)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76bc96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
